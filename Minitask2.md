**Related existing solutions in the market:**

We'll note down some existing solutions that tackle a similar problem statement to the one we are tackling, in order to see if there are any market
research insights and other inspiration that we can get from it.

1. **Hearing aids:**

- Patients with hearing loss tend to buy this. 
- Generally, hearing aids consist of a microphone, an amplifier and a speaker to amplify the sound heard. In our product, we only need to focus on the microphone.
- There are two types of hearing aids: Analog and Digital hearing aids. We can get some inspiration from the way these are designed to tackle our own problem.
- Analog aids need to be programmed specifically for a noisy or a quiet environment but can't work well in both these environments simultaneously. This is because
if the aid is programmed to work in a quiet environment, where it picks up any sound that stands out, it would amplify a lot of irrelevant sounds in a noisy 
environment. Therefore, it needs to be programmmed to amplify only to a certain extent depending on the situation.
- Digital aids are more versatile, as they convert sound waves into numerical codes, similar to the binary code of a computer, before amplifying them. 
Because the code also includes information about a soundâ€™s pitch or loudness, the aid can be specially programmed to amplify some frequencies more than others. 
These aids also can be programmed to focus on sounds coming from a specific direction. Digital circuitry can be used in all types of hearing aids.
- Effectively, digital hearing aids combat the noise problem and can ensure that irrelevant noises are not amplified. As this has been done before, we can apply
these concepts in our project as well (to find the direction of the sound and to cut off unnecessary noise before lighting up the glasses). 
- So, these digital hearing aids have multiple listening programs (different settings for which frequencies to pass through) that allow them to switch between 
modes automatically depending on the environment.
- Finally, they use a microphone array to capture the direction of the sound, and if one sound is of the appropriate frequency and is relatively loud, that direction
can be made relatively amplified while in the other directions, the sound can be reduced.

2. **Google glass:**

- It doesn't use the glasses for display, but rather uses a very small display chip to display anything that needs to be visible to the user. I personally feel that
having a display that is displaced from the regular viewing position might lead to slight eye strain, but we'll have to see if that works anyway. Ultimately, the
solution doesn't seem so difficult to implement if we do it in this way. 
- All the contents are shown on this small display chip. When you bring it closer to your eye, it looks a lot larger and you can see elements on it on various
locations on the screen. This is of course a possible way of representing the direction of sound, but as I mentioned it may have limitations.

